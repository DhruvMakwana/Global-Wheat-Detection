{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Global Wheat Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSgIVXLE8inufpt0fiN8EK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvMakwana/Global-Wheat-Detection/blob/master/Global_Wheat_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WTUYcID43Ak",
        "colab_type": "text"
      },
      "source": [
        "# Global Wheat Detection\n",
        "\n",
        "## Problem Overview:\n",
        "\n",
        "Open up your pantry and you’re likely to find several wheat products. Indeed, your morning toast or cereal may rely upon this common grain. Its popularity as a food and crop makes wheat widely studied. To get large and accurate data about wheat fields worldwide, plant scientists use image detection of \"wheat heads\"—spikes atop the plant containing grain. These images are used to estimate the density and size of wheat heads in different varieties. Farmers can use the data to assess health and maturity when making management decisions in their fields.\n",
        "\n",
        "However, accurate wheat head detection in outdoor field images can be visually challenging. There is often overlap of dense wheat plants, and the wind can blur the photographs. Both make it difficult to identify single heads. Additionally, appearances vary due to maturity, color, genotype, and head orientation. Finally, because wheat is grown worldwide, different varieties, planting densities, patterns, and field conditions must be considered. Models developed for wheat phenotyping need to generalize between different growing environments. Current detection methods involve one- and two-stage detectors (Yolo-V3 and Faster-RCNN), but even when trained with a large dataset, a bias to the training region remains.\n",
        "\n",
        "[The Global Wheat Head Dataset](http://www.global-wheat.com/2020-challenge/) is led by nine research institutes from seven countries: the University of Tokyo, Institut national de recherche pour l’agriculture, l’alimentation et l’environnement, Arvalis, ETHZ, University of Saskatchewan, University of Queensland, Nanjing Agricultural University, and Rothamsted Research. These institutions are joined by many in their pursuit of accurate wheat head detection, including the Global Institute for Food Security, DigitAg, Kubota, and Hiphen.\n",
        "\n",
        "In this competition, you’ll detect wheat heads from outdoor images of wheat plants, including wheat datasets from around the globe. Using worldwide data, you will focus on a generalized solution to estimate the number and size of wheat heads. To better gauge the performance for unseen genotypes, environments, and observational conditions, the training dataset covers multiple regions. You will use more than 3,000 images from Europe (France, UK, Switzerland) and North America (Canada). The test data includes about 1,000 images from Australia, Japan, and China.\n",
        "\n",
        "Wheat is a staple across the globe, which is why this competition must account for different growing conditions. Models developed for wheat phenotyping need to be able to generalize between environments. If successful, researchers can accurately estimate the density and size of wheat heads in different varieties. With improved detection farmers can better assess their crops, ultimately bringing cereal, toast, and other favorite dishes to your table.\n",
        "\n",
        "## Data:\n",
        "More details on the data acquisition and processes are available at https://arxiv.org/abs/2005.02162\n",
        "\n",
        "<b>Data Format:</b>\n",
        "The data is images of wheat fields, with bounding boxes for each identified wheat head. Not all images include wheat heads / bounding boxes. The images were recorded in many locations around the world.\n",
        "\n",
        "The CSV data is simple - the image ID matches up with the filename of a given image, and the width and height of the image are included, along with a bounding box. There is a row in train.csv for each bounding box. Not all images have bounding boxes.\n",
        "\n",
        "<b>Goal:</b> The goal is to predict bounding boxes around each wheat head in images that have them. If there are no wheat heads, you must predict no bounding boxes.\n",
        "\n",
        "<b>File Structure:</b>\n",
        "1. train.csv - the training data\n",
        "2. sample_submission.csv - a sample submission file in the correct format\n",
        "3. train.zip - training images\n",
        "4. test.zip - test images\n",
        "\n",
        "<b>Fields in csv:</b>\n",
        "1. image_id - the unique image ID\n",
        "2. width, height - the width and height of the images\n",
        "3. bbox - a bounding box, formatted as a Python-style list of [xmin, ymin, width, height]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIk5jzi579aA",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Exploratory Data Analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afITIZnc8gKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries\n",
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JIrf7LS77Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup directory and files\n",
        "base_dir = \"/content/drive/My Drive/Dataset\"\n",
        "train_dir = os.path.join(base_dir, 'Train/')\n",
        "test_dir = os.path.join(base_dir, 'Test/')\n",
        "train_dataframe = os.path.join(base_dir, 'train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7hJjE0889St",
        "colab_type": "code",
        "outputId": "95042958-c379-4345-f6b0-81407394f7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# number of images in train and test\n",
        "print(\"Number of Training images are: {}\".format(len(glob(train_dir + '*'))))\n",
        "print(\"Number of Testing images are: {}\".format(len(glob(test_dir + '*'))))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training images are: 3422\n",
            "Number of Testing images are: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHHAqbWG9nto",
        "colab_type": "text"
      },
      "source": [
        "As mentioned in problem overview we have only 10 testing images and other images are hidden which will be used at submission.\n",
        "\n",
        "We are having 3422 images for training which is not enough. So we need to augment our data to increase performance.\n",
        "\n",
        "We will cover Augmentation in step **Replace this with step number**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP6U2DQP-ZxY",
        "colab_type": "text"
      },
      "source": [
        "Its mentioned in problem overview that not all images are having bouding box. so lets check how many of the images are not having bounding box."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7_x2-qd-ZZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "571fd5d8-e4c1-4ee6-bf1d-076baa9289d1"
      },
      "source": [
        "# load dataframe\n",
        "df = pd.read_csv(train_dataframe)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>bbox</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[834.0, 222.0, 56.0, 36.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[226.0, 548.0, 130.0, 58.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[377.0, 504.0, 74.0, 160.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[834.0, 95.0, 109.0, 107.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[26.0, 144.0, 124.0, 117.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_id  width  height                         bbox   source\n",
              "0  b6ab77fd7   1024    1024   [834.0, 222.0, 56.0, 36.0]  usask_1\n",
              "1  b6ab77fd7   1024    1024  [226.0, 548.0, 130.0, 58.0]  usask_1\n",
              "2  b6ab77fd7   1024    1024  [377.0, 504.0, 74.0, 160.0]  usask_1\n",
              "3  b6ab77fd7   1024    1024  [834.0, 95.0, 109.0, 107.0]  usask_1\n",
              "4  b6ab77fd7   1024    1024  [26.0, 144.0, 124.0, 117.0]  usask_1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW35ujZr9UBm",
        "colab_type": "code",
        "outputId": "1bb4e37f-2ca5-40f1-e8d1-9929519d8303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "all_train_images = pd.DataFrame([fns.split('/')[-1][:-4] for fns in train_dir])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>bbox</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[834.0, 222.0, 56.0, 36.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[226.0, 548.0, 130.0, 58.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[377.0, 504.0, 74.0, 160.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[834.0, 95.0, 109.0, 107.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "      <td>[26.0, 144.0, 124.0, 117.0]</td>\n",
              "      <td>usask_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_id  width  height                         bbox   source\n",
              "0  b6ab77fd7   1024    1024   [834.0, 222.0, 56.0, 36.0]  usask_1\n",
              "1  b6ab77fd7   1024    1024  [226.0, 548.0, 130.0, 58.0]  usask_1\n",
              "2  b6ab77fd7   1024    1024  [377.0, 504.0, 74.0, 160.0]  usask_1\n",
              "3  b6ab77fd7   1024    1024  [834.0, 95.0, 109.0, 107.0]  usask_1\n",
              "4  b6ab77fd7   1024    1024  [26.0, 144.0, 124.0, 117.0]  usask_1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDk_h76j_pDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}